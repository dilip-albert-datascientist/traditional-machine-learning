{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A UK based e-commerce company want to divide their customer into egments and develop marketing strategies according to this segmentation results. \n",
    "Data Set Story:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Online+Retail+II \n",
    "\n",
    "This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011.\n",
    "\n",
    "Item listed are souvenirs and gift item.\n",
    "\n",
    "Majority of the customers  are wholesale traders.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "    • InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation.\\n\n",
    "    • StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each product.\\n\n",
    "    • Description: Item name and description. Nominal.\\n\n",
    "    • Quantity: The quantities of each  item per transaction. Numeric.\\n\n",
    "    • InvoiceDate: Invoice date and time. Numeric.\\n\n",
    "    • UnitPrice: Unit price. Numeric. Product price per unit (£).\\n\n",
    "    • CustomerID: Customer number. Nominal. A 5-digit  number uniquely assigned to each customer.\\n\n",
    "    • Country: Country name. Nominal. The name of the country where a customer resides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to import excel files xlrd and opepyxl shoud be installed. By using pip indtall you can isntall them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firs step is importing needed libraries: numpy, pandas and datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ = pd.read_excel(\"../input/uci-online-retail-ii-data-set/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\" ) \n",
    "df = df_.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading data set, we are trying to get general information about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"StockCode\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total quantity for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"StockCode\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items ordered most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"StockCode\").agg({\"Quantity\": \"sum\"}).sort_values(\"Quantity\", ascending=False).head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Invoice\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting familiar with the dataset, we are preparing data for analysis. For this case we are going to drop null values, clear out thereturned items. For this analysis outliers are neglected so we are not going to do any operation about outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping out null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invocies starting with \"C\" are either cancelled or returned goods so we are dropping out the item from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df[\"Invoice\"].str.contains(\"C\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also clear any items Quantity less than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[(df[\"Quantity\"]>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are startig with addin TotalPrice column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TotalPrice\"]=df[\"Quantity\"]*df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate Recency value, we nned last transaction date. \n",
    "We fix the analysis date 2 days after the last transaction date to get resanable recency values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last transaction date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InvoiceDate\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = dt.datetime(2011, 12, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are forming a Data Frame for Customer ID withthe variables of InvoiceDate(will be changed to Rececny in next step), Invoice number(will be changed to \"Frequency\") and Total sum of transactions(will be changed to \"Monetary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = df.groupby('Customer ID').agg({'InvoiceDate': lambda date: (today_date - date.max()).days,\n",
    "                                     'Invoice': lambda num: num.nunique(),\n",
    "                                     'TotalPrice': lambda TotalPrice: TotalPrice.sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reassing the column names in previous cell. \n",
    "Recency: We subtracted today's date from the last transation date to calculate recency\n",
    "Frequency: We counted invoiced per each customer. Since each invoice refers to one transaction we can use them as frequency.\n",
    "Monetary: We sum up all transations per each customer as their monetary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.columns = ['Recency', 'Frequency', 'Monetary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid miscalculation we run a acheck querry to eleminate 0 values in Monetary and Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = rfm[(rfm[\"Monetary\"]) > 0 & (rfm[\"Frequency\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide all the score into 5 categories with qcut function where 5 is the best and 1 is the worst.\n",
    "For Frequency most recent transaction is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"RecencyScore\"] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"FrequencyScore\"] = pd.qcut(rfm['Frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"MonetaryScore\"] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating  RFM scores, we  combine scores as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[\"RFM_SCORE\"] = (rfm['RecencyScore'].astype(str) +\n",
    "                    rfm['FrequencyScore'].astype(str) +\n",
    "                    rfm['MonetaryScore'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create segment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map = {\n",
    "    r'[1-2][1-2]': 'Hibernating',\n",
    "    r'[1-2][3-4]': 'At_Risk',\n",
    "    r'[1-2]5': 'Cant_Loose',\n",
    "    r'3[1-2]': 'About_to_Sleep',\n",
    "    r'33': 'Need_Attention',\n",
    "    r'[3-4][4-5]': 'Loyal_Customers',\n",
    "    r'41': 'Promising',\n",
    "    r'51': 'New_Customers',\n",
    "    r'[4-5][2-3]': 'Potential_Loyalists',\n",
    "    r'5[4-5]': 'Champions'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a new column to rfm dataframe as \"Segment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['Segment'] = rfm['RecencyScore'].astype(str) + rfm['FrequencyScore'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['Segment'] = rfm['Segment'].replace(seg_map, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General statistics for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[[\"Segment\", \"Recency\", \"Frequency\", \"Monetary\"]].groupby(\"Segment\").agg([\"mean\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm[[\"Segment\", \"Recency\", \"Frequency\", \"Monetary\"]].groupby(\"Segment\").agg([\"mean\", \"count\",\n",
    "                                                                             \"min\", \"median\", \"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expoert desired segments and customer number as csv wıth following codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df[\"Loyal_Customers\"] = rfm[rfm[\"Segment\"] == \"Loyal_Customers\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#new_df[\"Loyal_Customers\"] = rfm[rfm[\"Loyal_customers\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.to_excel(\"Loyal_Customers.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
