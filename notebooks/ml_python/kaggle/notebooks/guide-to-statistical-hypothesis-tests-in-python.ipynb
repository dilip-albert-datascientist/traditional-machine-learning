{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 class=\"list-group-item list-group-item-action active\">Guide to Statistical Hypothesis Tests in Python</h1>\n\n\n<img src = \"https://d33wubrfki0l68.cloudfront.net/a5cb4bbe1b04d9099c6fc771724ea67ec087845b/cb16f/wp-content/uploads/2019/07/statistics-vs-machine-learning.png\">\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content:</h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">1. Normality Tests<span class=\"badge badge-primary badge-pill\">1</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#two_\" role=\"tab\" aria-controls=\"messages\">2. Correlation Tests<span class=\"badge badge-primary badge-pill\">2</span></a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#three_\" role=\"tab\" aria-controls=\"settings\">3. Stationary Tests<span class=\"badge badge-primary badge-pill\">3</span></a>\n   <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#four_\" role=\"tab\" aria-controls=\"settings\">4. Parametric Statistical Hypothesis Tests<span class=\"badge badge-primary badge-pill\">4</span></a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#five_\" role=\"tab\" aria-controls=\"settings\">5. Non-Parametric Statistical Hypothesis Tests<span class=\"badge badge-primary badge-pill\">5</span></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to carry out any Machine learning Projects Probability and Statistics plays a major role.Probability deals with \npredicting the likelihood of future events however Statistics deals with analyse frequency of past events.\n"},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\">Normality Tests</h2>\n<p> Main obejctive of performing Normality Tests is to validate the Gaussian distribution of data. </p>\n<h3 class=\"alert alert-info\">Shapiro-Wilk Test</h3>\nTests whether a data sample has a Gaussian distribution.\n\n<div class=\"alert alert-info\">Assumption</div>\n Observations in each sample are independent and distributed identically.\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the sample has a Gaussian distribution.\n* H1: the sample does not have a Gaussian distribution.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = shapiro(data)\nprint('stat={0:.3f}, p={0:.3f}' .format(stat, p))\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">D’Agostino’s K^2 Test</h3>\nTests whether a data sample has a Gaussian distribution.\n\n<div class=\"alert alert-info\">Assumption</div>\n Observations in each sample are independent and distributed identically.\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the sample has a Gaussian distribution.\n* H1: the sample does not have a Gaussian distribution.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the D'Agostino's K^2 Normality Test\nfrom scipy.stats import normaltest\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = normaltest(data)\nprint('stat={0:.3f}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Anderson-Darling Test</h3>\nTests whether a data sample has a Gaussian distribution.\n\n\n<div class=\"alert alert-info\">Assumption</div>\n Observations in each sample are independent and distributed identically.\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the sample has a Gaussian distribution.\n* H1: the sample does not have a Gaussian distribution.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Example of the Anderson-Darling Normality Test\nfrom scipy.stats import anderson\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nresult = anderson(data)\nprint('stat={0:.3g}'.format(result.statistic))\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic < cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\">Correlation Tests</h2>\n<p> Correlation Tests are used to check the correlation between two independent features or variables. </p>\n\n<h3 class=\"alert alert-info\">Pearson’s Correlation Coefficient</h3>\nTests whether a data sample is linearly separable.\n\n<div class=\"alert alert-info\">Assumption</div>\na) Observations in each sample are independent and distributed identically. <br>\nb) Observations are normally distributed. <br>\nc) Similar variance between independent variables\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the samples are correlated.\n* H1: the sample does not have any correlation.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Pearson's Correlation test\nfrom scipy.stats import pearsonr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = pearsonr(data1, data2)\nprint('stat={0:.3f}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Spearman’s Rank Correlation</h3>\nTests whether a data sample is montonically separable.\n\n<div class=\"alert alert-info\">Assumption</div>\na) Observations in each sample are independent and distributed identically. <br>\nb) Observations in each sample are ranked . <br>\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the samples are correlated.\n* H1: the sample does not have any correlation.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Spearman's Rank Correlation Test\nfrom scipy.stats import spearmanr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = spearmanr(data1, data2)\nprint('stat={0:.3g}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Kendall’s Rank Correlation</h3>\nTests whether a data sample is montonically separable.\n\n<div class=\"alert alert-info\">Assumption</div>\na) Observations in each sample are independent and distributed identically. <br>\nb) Observations in each sample are ranked . <br>\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the samples are correlated.\n* H1: the sample does not have any correlation.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Kendall's Rank Correlation Test\nfrom scipy.stats import kendalltau\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = kendalltau(data1, data2)\nprint('stat={0:.3f}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Chi-Squared Test</h3>\nTests whether two categorical variables are related to each other.\n\n<div class=\"alert alert-info\">Assumption</div>\na) Observations in used in contengency table are Independent. <br>\nb) There are more than 25 examples in contengency table . <br>\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the samples are correlated.\n* H1: the sample does not have any correlation.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Chi-Squared Test\nfrom scipy.stats import chi2_contingency\ntable = [[10, 20, 30],[6,  9,  17]]\nstat, p, dof, expected = chi2_contingency(table)\nprint('stat={0:.3g}, p={0:.3f}' .format(stat, p))\nif p > 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\">Stationary Tests</h2>\n<p> Used for Validating the Time series data trends(Stationary/Not-Stationary). </p>\n<h3 class=\"alert alert-info\">Augmented Dickey-Fuller Unit Root Test</h3>\nTests whether a Time series data has autoregressive trend.\n\n<div class=\"alert alert-info\">Assumption</div>\n Data Instance have temporality.\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the unit root is present.\n* H1: the unit root not present.\n\n<a href=\"https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html\" class=\"btn btn-warning\" role=\"button\">Stats-Model Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Augmented Dickey-Fuller unit root test\nfrom statsmodels.tsa.stattools import adfuller\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, obs, crit, t = adfuller(data)\nprint('stat={0:.3f}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably not Stationary')\nelse:\n    print('Probably Stationary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Kwiatkowski-Phillips-Schmidt-Shin</h3>\nTests whether a Time series trend is stationary or not.\n\n<div class=\"alert alert-info\">Assumption</div>\n Data Instance have temporality.\n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the stationarity is present.\n* H1: the stationarity not present.\n\n<a href=\"https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.kpss.html#statsmodels.tsa.stattools.kpss\" class=\"btn btn-warning\" role=\"button\">Stats-Model Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Kwiatkowski-Phillips-Schmidt-Shin test\nfrom statsmodels.tsa.stattools import kpss\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, crit = kpss(data)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably not Stationary')\nelse:\n    print('Probably Stationary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\">Parametric Statistical Hypothesis Tests</h2>\n<p> Statistical Test for comaparison between data samples. </p>\n<h3 class=\"alert alert-info\">Student’s t-test</h3>\nAverage between two data samples are significantly different.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations are normally distributed.<br>\nc)Observations have same variance between each other. <br>\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the mean between two samples are equal .\n* H1: the  mean between two samples are not equal.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Student's t-test\nfrom scipy.stats import ttest_ind\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_ind(data1, data2)\nprint('stat={0:.3f}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Paired Student’s t-test</h3>\nAverage between two data samples are significantly different.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations are normally distributed. <br>\nc)Observations have same variance between each other. <br>\nd)Observations are paired.\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the mean between two samples are equal .\n* H1: the  mean between two samples are not equal.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Paired Student's t-test\nfrom scipy.stats import ttest_rel\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_rel(data1, data2)\nprint('stat={0:.3f}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Analysis of Variance Test (ANOVA)</h3>\nAverage between two data samples are significantly independent and different.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations are normally distributed. <br>\nc)Observations have same variance between each other. <br>\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the mean between two samples are equal .\n* H1: the  mean between two samples are not equal.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Analysis of Variance Test\nfrom scipy.stats import f_oneway\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = f_oneway(data1, data2, data3)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Repeated Measures ANOVA Test</h3>\nAverage between two or more paired samples are significantly different.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations are normally distributed. <br>\nc)Observations have same variance between each other. <br>\nd)Observation can be paired.\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the mean between two samples are equal .\n* H1: the  mean between two samples are not equal.\n\n<div class=\"alert alert-warning\">No Python Implementation Available till now.</div>\n"},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\">Nonparametric Statistical Hypothesis Tests</h2>\n<h3 class=\"alert alert-info\">Mann-Whitney U Test</h3>\nDistribution of two data samples are equal or not.\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations in each data samples can be ranked.<br>\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the distribution of two samples are equal .\n* H1: the  distribution of two samples are not equal.\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Mann-Whitney U Test\nfrom scipy.stats import mannwhitneyu\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = mannwhitneyu(data1, data2)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Wilcoxon Signed-Rank Test</h3>\nDistribution between two paired samples are significantly equal or not.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations can be ranked. <br>\nc)Observations are paired. <br>\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the distribution of two samples are equal .\n* H1: the  distribution of two samples are not equal.\n\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Wilcoxon Signed-Rank Test\nfrom scipy.stats import wilcoxon\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = wilcoxon(data1, data2)\nprint('stat={0:.3g}, p={0:.3g}' .format (stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Kruskal-Wallis H Test</h3>\nDistribution between two independent samples are significantly equal or not.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations can be ranked. <br>\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the distribution of  samples are equal .\n* H1: the  distribution of  samples are not equal.\n\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Kruskal-Wallis H Test\nfrom scipy.stats import kruskal\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = kruskal(data1, data2)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"alert alert-info\">Friedman Test</h3>\nDistribution between two paired samples are significantly equal or not.\n\n<div class=\"alert alert-info\">Assumption</div>\na)Each data sample's observation are independent and distributed. <br>\nb)Observations can be ranked. <br>\nc)Observations can be paired.\n \n<div class=\"alert alert-info\">Hypothesis</div>\n\n\n* H0: the distribution of  all samples are equal .\n* H1: the  distribution of  one or more samples are not equal.\n\n\n<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.friedmanchisquare.html\" class=\"btn btn-warning\" role=\"button\">Scipy Ref -></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of the Friedman Test\nfrom scipy.stats import friedmanchisquare\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = friedmanchisquare(data1, data2, data3)\nprint('stat={0:.3g}, p={0:.3f}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-warning\">Above some of the key Statistical Tests that can be used in any Machine learning Projects.These test can be used in normality validation, establishing relationships between variables, and differences between samples.</div>\n\n<div class = \"alert alert-info\"> Thumbs Up if you find it useful 👍 Cheers!!!! </div>\n<div class=\"alert alert-info\">Reference-</div>\n\n-> [Weblink](https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/?fbclid=IwAR0inTph5-QpLK1HPfSXVIQdyg7_m00djV9TnE5Y7dGDxeD5lfiaf2ZsKh0)\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}