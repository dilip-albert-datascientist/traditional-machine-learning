{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Complete Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Bespoke EDA Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0. Questions To Ask Before You Download the Data\n",
    "\n",
    "I called this one step 0 because it happens before you import data into Python. \n",
    "It’s easy to forget, but if you can answer these questions it can save you a lot of time and frustration down the road.\n",
    "    How was this data collected/where did it come from?\n",
    "    \n",
    "    Why am I interested in this data?\n",
    "    \n",
    "    What would be the target variable of interest? (if applicable)\n",
    "    \n",
    "    Is this data from a reputable source?\n",
    "    \n",
    "    Is there enough data here to make an ML model?\n",
    "    \n",
    "    Have other people conducted a similar analysis/modeling project on this dataset? Do I want to be able to learn from their conclusions or create a novel project?\n",
    "    \n",
    "    Is there a data dictionary for the dataset? Is it complete?\n",
    "    \n",
    "    Are there any additional challenges or problems that I anticipate if I use this data?\n",
    "    \n",
    "    It’s helpful to use these questions like a filter when you have a choice on what dataset to use.\n",
    "    \n",
    "    It’s really tough to realize halfway through a project that you picked a bad dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Structure & Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions to answer:\n",
    "    How many features do you have?\n",
    "    How many observations do you have?\n",
    "    What is the data type of each feature?\n",
    "    \n",
    "    From what you know about the features of your dataset, do the data types make sense? Do you need to change any?\n",
    "\n",
    "    Example: Your data has a Customer ID number for every row, and each number is five digits long, stored as an integer. \n",
    "        You will not ever be aggregating or analyzing the Customer ID like an integer, so you should change it to the “object” data type.\n",
    "    \n",
    "    Do you have null values? (to be fixed later)\n",
    "    \n",
    "    How much memory does this dataset use? Could this pose a problem for you later on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many features do you have?\n",
    "#### How many observations do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the data type of each feature?\n",
    "#### From what you know about the features of your dataset, do the data types make sense? \n",
    "#### Do you need to change any data types?\n",
    "#### Do you have null values? (to be fixed later)\n",
    "\n",
    "#### How much memory does this dataset use? \n",
    "#### Could this pose a problem for you later on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions to answer:\n",
    "Are the max/min values reasonable for the variables? Do you see any values that look like errors?\n",
    "What is the mean for each variable? What do the means tell you about your dataset as a whole?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to answer:\n",
    "#### What is the distribution of each variable?\n",
    "#### Do there appear to be outliers? (to be fixed later)\n",
    "#### Think about what the variables mean and what the histograms say about their values and their spread — are there any surprises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Null Values & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions to answer:\n",
    "Is the null value a result of the way data was recorded?\n",
    "Example: Survey response data is recorded in columns as “yes”, “no,” and a null value for “prefer not to answer.” In this case, all nulls can be filled in with a single value like “no answer.”\n",
    "Can you drop the rows with null values without it significantly affecting your analysis?\n",
    "Looking at the distributions of the variables, can you justify filling in the missing values with the mean or median for that variable?\n",
    "Be careful! You have to deal with missing values somehow, but sometimes it is better to drop rows rather than tinker with the original data because if you put bad data into a model you cannot get meaningful results.\n",
    "If your data is time-series data, can you fill the missing values with interpolation?\n",
    "Are there so many missing values for a variable that you should drop that variable from your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions to ask:\n",
    "Do you have outliers (represented as dark circles on the boxplots) in your variables?\n",
    "Why do you think you have outliers?\n",
    "Do the outliers represent real observations (i.e. not errors)?\n",
    "Should you exclude these observations? If not, should you winsorize the values?\n",
    "\n",
    "This is a tricky question. I typically identify my outliers and then I leave them be until I have tried out some models. \n",
    "If I find the models have low accuracy, I will go back and re-evaluate whether I should winsorize the variable(s) with outliers (if I have no other options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Correlations/Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions to ask:\n",
    "Which variables are most correlated with your target variable? (If applicable)\n",
    "Is there multicollinearity? (Two features that have a correlation > 0.8) How will this affect your model?\n",
    "Do you have variables that represent the same information? Can one be dropped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The most common transformation is one-hot-encoding to transform categorical variables into numeric — binary, to be specific — variables. \n",
    "This is necessary because machine learning models cannot handle “object” data types. Pandas makes this easy to do:\n",
    "\n",
    "new_df = pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Another common transformation (which is necessary for some models) is standardizing variables. \n",
    "Here is the code for that:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, you may want to transform variables so that they follow a normal distribution, depending on the model you are using. \n",
    "For this, you can try np.log() , np.sqrt() , the box-cox transformation, and other functions to transform your data to better fit a normal distribution."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
